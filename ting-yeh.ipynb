{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the Data \n",
    "df=pd.read_csv(\"movie_metadata.csv\")\n",
    "#Displaying the first 5 records\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping useless columns \n",
    "df.drop('movie_title',axis=1,inplace=True)\n",
    "df.drop('language',axis=1,inplace=True)\n",
    "df.drop('plot_keywords',axis=1,inplace=True)\n",
    "df.drop('genres',axis=1,inplace =True)\n",
    "df.drop('movie_imdb_link', axis=1, inplace=True)\n",
    "df.drop('color',axis=1,inplace=True)\n",
    "df.drop('actor_1_name',axis=1,inplace=True)\n",
    "df.drop('actor_2_name',axis=1,inplace=True)\n",
    "df.drop('actor_3_name',axis=1,inplace=True)\n",
    "df.drop('director_name', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the null values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deal with missing values in the dataset\n",
    "df.dropna(axis=0,subset=['num_critic_for_reviews', 'duration',\n",
    "       'director_facebook_likes', 'actor_3_facebook_likes',\n",
    "       'actor_1_facebook_likes', 'gross', 'num_voted_users',\n",
    "       'cast_total_facebook_likes', 'facenumber_in_poster',\n",
    "       'num_user_for_reviews', 'country', 'content_rating', 'budget',\n",
    "       'title_year', 'actor_2_facebook_likes', 'imdb_score', 'aspect_ratio',\n",
    "       'movie_facebook_likes'],inplace=True)\n",
    "\n",
    "#Replacing valus\n",
    "df[\"content_rating\"].fillna(\"R18\", inplace = True) \n",
    "df[\"aspect_ratio\"].fillna(df[\"aspect_ratio\"].median(),inplace=True)\n",
    "df[\"budget\"].fillna(df[\"budget\"].median(),inplace=True)\n",
    "df['gross'].fillna(df['gross'].median(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the null values again\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing the duplicate values in the datset\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine facebook likes of actor 2 and actor 3\n",
    "df['Other_actor_facebbok_likes']=df[\"actor_2_facebook_likes\"] + df['actor_3_facebook_likes']\n",
    "df.drop('actor_2_facebook_likes',axis=1,inplace=True)\n",
    "df.drop('actor_3_facebook_likes',axis=1,inplace=True)\n",
    "df.drop('cast_total_facebook_likes',axis=1,inplace=True)\n",
    "#create the ratio of num_user_for_reviews and num_critic_for_reviews.\n",
    "df['critic_review_ratio']=df['num_critic_for_reviews']/df['num_user_for_reviews']\n",
    "df.drop('num_critic_for_reviews',axis=1,inplace=True)\n",
    "df.drop('num_user_for_reviews',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix shown in the figure \n",
    "corr = df.corr()\n",
    "sns.set_context(\"notebook\", font_scale=1.0, rc={\"lines.linewidth\": 2.5})\n",
    "plt.figure(figsize=(13,7))\n",
    "a = sns.heatmap(corr, annot=True, fmt='.2f')\n",
    "rotx = a.set_xticklabels(a.get_xticklabels(), rotation=90)\n",
    "roty = a.set_yticklabels(a.get_yticklabels(), rotation=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deal with categorical data\n",
    "value_counts=df[\"country\"].value_counts()\n",
    "vals = value_counts[:2].index\n",
    "df['country'] = df.country.where(df.country.isin(vals), 'other')\n",
    "df = pd.get_dummies(data = df, columns = ['country'] , prefix = ['country'] , drop_first = True)\n",
    "df = pd.get_dummies(data = df, columns = ['content_rating'] , prefix = ['content_rating'] , drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotHistogram(df,col,tit='',xlabel='',ylabel='',log=False):\n",
    "    bins = np.linspace(df[col].min(),df[col].max(),25)\n",
    "    plt.xlim([df[col].min(),df[col].max()])\n",
    "    plt.hist(df[col], bins=bins, alpha=0.5,log=log)\n",
    "    plt.title(tit)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()\n",
    "\n",
    "plotHistogram(df,'imdb_score',ylabel='# of films',xlabel='imdb_score',tit='imdb_score logarithmic histogram',log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = list(df.select_dtypes(include='object').columns)\n",
    "num_cols = list(df.select_dtypes(exclude='object').columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(18, 6))\n",
    "sns.regplot(x=df['budget'].apply(np.log10), y=df['gross'], ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(14, 6))\n",
    "sns.barplot(x=df['imdb_score'].apply(np.round), y=df['gross'], ax=ax)\n",
    "\n",
    "plt.xlabel('IMDB Score'); plt.xlabel('Year');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorize the imdb values to new columns imdb_score_y\n",
    "df[\"imdb_score_y\"]=pd.cut(df['imdb_score'], bins=[0,4,6,8,10], right=True, labels=False)+1\n",
    "df.drop('imdb_score',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and testing data\n",
    "X=pd.DataFrame(columns=['num_critic_for_reviews', 'duration', 'director_facebook_likes',\n",
    "       'actor_3_facebook_likes', 'actor_1_facebook_likes', 'gross',\n",
    "       'num_voted_users', 'cast_total_facebook_likes', 'facenumber_in_poster',\n",
    "       'num_user_for_reviews', 'budget', 'title_year',\n",
    "       'actor_2_facebook_likes', 'aspect_ratio', 'movie_facebook_likes',\n",
    "       'country_USA', 'country_other', 'content_rating_G',\n",
    "       'content_rating_GP', 'content_rating_M', 'content_rating_NC-17',\n",
    "       'content_rating_Not Rated', 'content_rating_PG', 'content_rating_PG-13',\n",
    "       'content_rating_Passed', 'content_rating_R', 'content_rating_Unrated',\n",
    "       'content_rating_X'],data=df)\n",
    "y=pd.DataFrame(columns=['imdb_score_y'],data=df)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.3,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logit =LogisticRegression()\n",
    "logit.fit(X_train,np.ravel(y_train,order='C'))\n",
    "y_pred=logit.predict(X_test)\n",
    "\n",
    "#Confusion matrix for logistic regression**\n",
    "from sklearn import metrics\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(cnf_matrix)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=22)\n",
    "knn.fit(X_train, np.ravel(y_train,order='C'))\n",
    "knnpred = knn.predict(X_test)\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, knnpred)\n",
    "print(cnf_matrix)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, knnpred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators = 200)#criterion = entopy,gini\n",
    "rfc.fit(X_train, np.ravel(y_train,order='C'))\n",
    "rfcpred = rfc.predict(X_test)\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, rfcpred)\n",
    "print(cnf_matrix)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, rfcpred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Comparison\n",
    "from sklearn.metrics import classification_report\n",
    "print('Logistic  Reports\\n',classification_report(y_test, y_pred))\n",
    "print('KNN Reports\\n',classification_report(y_test, knnpred))\n",
    "print('Random Forests Reports\\n',classification_report(y_test, rfcpred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The conclusion is that Random Forest Algorithm have best accuracy which is around 77%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
